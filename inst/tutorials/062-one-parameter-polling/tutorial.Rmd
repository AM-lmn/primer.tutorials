---
title: 'One Parameter: Polling'
author: Ryan Southward
tutorial:
  id: one-parameter-polling
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: Use polling data from the 2013 election to answer questions about support
  for President Obama.
---

```{r setup, include = FALSE}
library(learnr)
library(primer.tutorials)
library(tidyverse)
library(primer.data)
library(rstanarm)
library(skimr)
knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local") 

# Create a fake data set with polling data.


set.seed(17)
iop <- tibble(response = c(rep("Approve", 855),
                                 rep("Disapprove", 1124),
                                 rep(NA, 110))) %>% 
  sample_frac()

class <- tibble(response = c(rep("Approve", 64),
                                 rep("Disapprove", 104),
                                 rep(NA, 32))) %>% 
  sample_frac()

# Replicate the results w/o NA values to have students practice dropping NA values. 

iop_results <- iop %>%
  count(response) %>%
  drop_na()

class_results <- class %>%
  count(response) %>%
  drop_na()

# Posterior creation

iop_data <- tibble(approve = c(rep(1, 855), rep(0, 1124)))

# iop_fit <- stan_glm(data = iop_data,
#                     refresh = 0,
#                     seed = 2013,
#                     family = binomial,
#                     formula = approve ~ 1)
# 
# write_rds(iop_fit, "data/iop_fit.rds")

iop_fit <- read_rds("data/iop_fit.rds")

ob_iop_ppd <- posterior_epred(iop_fit, 
                          newdata = tibble(constant = 1)) %>%
  as_tibble() %>%
  rename(approval = `1`) %>%
  mutate(study = "iop")

class_data <- tibble(approve = c(rep(1, 64), rep(0, 104)))

# class_fit <- stan_glm(data = class_data,
#                     refresh = 0,
#                     seed = 2013, 
#                     family = binomial,
#                     formula = approve ~ 1) 

# write_rds(class_fit, "data/class_fit.rds")

class_fit <- read_rds("data/class_fit.rds")

class_ppd <- posterior_epred(class_fit, 
                          newdata = tibble(constant = 1)) %>%
  as_tibble() %>%
  rename(approval = `1`) %>%
  mutate(study = "class")

# Predicting outcomes: 

iop_predictions <- posterior_predict(iop_fit, 
                                     newdata = tibble(constant = rep(1, 20))) %>%
  as_tibble() %>%
  mutate(total = rowSums(across(`1`:`20`))) %>%
  select(total) %>%
  mutate(poll = "IOP poll")

class_predictions <- posterior_predict(class_fit, 
                                     newdata = tibble(constant = rep(1, 20))) %>%
 as_tibble() %>%
  mutate(total = rowSums(across(`1`:`20`))) %>%
  select(total) %>%
  mutate(poll = "Class poll")
  

# Probability question:

young <- tibble(num_people = 1:20) %>%
  mutate(predictions = map(num_people, ~ 
                             posterior_predict(iop_fit, 
                                               newdata = tibble(constant = rep(1, .))))) %>%
  mutate(total = map(predictions, ~ rowSums(.))) %>%
  unnest(total) %>%
  group_by(num_people, total) %>%
  summarize(num_draws = n(), .groups = "drop")

all <- tibble(num_people = 1:20) %>%
  mutate(predictions = map(num_people, ~ 
                             posterior_predict(class_fit, 
                                               newdata = tibble(constant = rep(1, .))))) %>%
  mutate(total = map(predictions, ~ rowSums(.))) %>%
  unnest(total) %>%
  group_by(num_people, total) %>%
  summarize(num_draws = n(), .groups = "drop") 

both_polls <- inner_join(all, young, by = c("num_people", "total")) %>%
  rename(all_draws = num_draws.x, young_draws = num_draws.y) 
```

```{r copy-code-chunk, child = "../../child_documents/copy_button.Rmd"}

```

```{r info-section, child = "../../child_documents/info_section.Rmd"}

```

<!-- 3) When comparing two surveys of different sizes, inferences about future samples differ much less than you might expect. Main difference is that smaller survey predicts that outlier events are (very slightly!) more like likely.  -->

<!-- RS: Because the second survey we use in this tutorial has a different value of p, it would be difficult to prove this point. -->

## Introduction
### 

Polls are a common application of binomial distributions, as respondents who agree can be represented by `1`, and respondents who disagree as `0`. Historically, presidential approval polls are a very well documented type of poll, where participants respond whether or not they approve of the current president in office. For the remainder of this tutorial, you'll examine the approval of President Obama in 2013. 

First, you will examine data from a 2013 approval poll for President Obama conducted by the Harvard Kennedy Institute of Politics, using *Widsom* and *Justice* to determine whether or not it can answer our questions. Next, you will calculate feasible values for the percentage of young Americans who approved of President Obama by creating a posterior distribution using the professional **rstanarm** statistical library. You will then compare the posterior of the Harvard IOP poll with another poll conducted by a government class using their centers and spreads. Finally, you will answer a challenging probability question by calculating the area under a graph. 

## Wisdom
### 

Before creating models, use *Wisdom* to determine whether or not the data you have is close enough to the data you need to answer your question.

### 

Imagine that it is November 15, 2013. Our question: What percentage of young people (aged 18 to 29) approve of President Obama's performance?  We will use the 2013 Harvard Institute of Politics (IOP) polling data collected from October 29 and November 13 to answer the question.


### Exercise 1

In two sentences, describe the Preceptor Table which could be used to answer our question. Specify what types of people would be included in the rows, and the necessary columns of data to answer the question. As a hint, there should be two columns.

```{r wisdom-1}
question_text(NULL,
	message = "The Preceptor Table includes a row for every person in the US who is 18 to 29. It has two columns: an ID column and column which indicates whether or not the person approves, on November 15, of President Obama's performance.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Because our question asks us for President Obama's approval rating on *November 15, 2013*, the data to fill in our Preceptor Table should come from that exact day. 

### Exercise 2

In one sentence, explain whether this model is causal or predictive, and why.

```{r wisdom-2}
question_text(NULL,
	message = "The model is predictive because there is only one potential outcome for each person: their approval (or not), November 15, 2015, of President Obama's performance.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Because our model is predictive, we must only worry about one column of outcome data. 

### Exercise 3

Between October 29 and November 13 of 2013, a team from Harvard's Institute of Politics [conducted their Fall 2013 Poll](https://iop.harvard.edu/sites/default/files_new/Harvard_PressReleaseFall2013%20.pdf) with 2,089 young Americans aged 18 to 29. Type `iop` to view the results of the poll.   


```{r wisdom-3, exercise = TRUE}

```

### 

The data we use comes from the yearly Harvard Public Opinion Project conducted by the Harvard Kennedy School Institute of Politics: 

> The Harvard Public Opinion Project conducts a biannual poll examining the political opinions and civic engagement of young Americans ages 18 to 29. Since its conception by two Harvard undergraduate students in 2000, the Harvard Public Opinion Project has provided the most comprehensive look at the political opinions, voting trends, and views on public service held by young Americans (iop.harvard.edu).

### Exercise 4

In the results we appear to see three possible responses: approve, disapprove, or NA. Let's use `skim()` from the **skimr** package on `iop` to confirm this. 


```{r wisdom-4, exercise = TRUE}

```

```{r wisdom-4-hint-1, eval = FALSE}
skim(...)
```

### 

Looking at n_unique for our single character column, we see that there are only 2 unique values. We also see that there are 110 missing values. This corresponds with our initial belief that there are only 3 possible values: approve, disapprove, or NA. Always take a thorough look at your data to make sure there are not hidden levels that are not visible at first glance. 

### Exercise 5

Although `skim()` identifies how many levels each column in our data has, it does not display the frequencies of each level. To do this, start a pipe with `iop`, and pipe on the function `count()`. Within `count()`, use the sole argument `response`. 


```{r wisdom-5, exercise = TRUE}

```

```{r wisdom-5-hint-1, eval = FALSE}
... %>%
  count(...)
```

### 

In effect we have created a summary of the Harvard IOP poll: Out of the 2,089 poll respondents, 855  approved of President Obama, 1124 disapproved, and answers are missing from 110. 

### Exercise 6

Why are there some NA values? Some respondents of the Harvard IOP declined to answer whether or not they approved of President Obama. Assuming the absence of non-response bias, NA values should be dropped to focus our attention on the ratio between approvals and disapprovals. Copy your code from above and continue your pipe with `drop_na()`. Save your tibble to an object named `iop_results`. 


```{r wisdom-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

### 

Hopefully people who approve and disapprove of President Obama are equally likely to decline to answer, which would indicate non-responses are more a result of the poll design rather than people's actual beliefs.

### Exercise 7

Finally, write two sentences proposing a reason why we can not consider the Preceptor Table and the data to come from the same population.

```{r wisdom-7}
question_text(NULL,
	message = "If there was a major news event on November 14th, then the data is from a different population than the Preceptor Table since the later was gathered on the two weeks before and the Preceptor Table requires data from November 15th.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Before creating models, use *Wisdom* to determine whether or not the data you have is close enough to the data you need to answer your question.

## Justice
### 

Use Justice to further increase your understanding of the situation at hand. Justice always consists of a Population Table, validity, stability, representativeness, and the Data Generating Mechanism.

### Exercise 1

In one sentence, state a wider Population that the Harvard IOP poll may generalize which encompasses both the Data and the Preceptor Table. Make sure to include demographic characteristics, as well as a specific time period. 

```{r justice-1}
question_text(NULL,
	message = "A wider population may be Americans aged 18-29 on day to day basis from October 27 to November 15, 2013.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

People's opinions changed, so someone may not have had the same attitude when they were surveyed as they did a few days prior. As such, it's important to track members of the Population over multiple days. 

### Exercise 2

In one sentence, state the columns that the Population Table should have. Hint: there should be 4. 

```{r justice-2}
question_text(NULL,
	message = "ID, Source, Time, Approval",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Every Population Table has a source column that identifies if the subject is from the Data, Preceptor Table, or Population, a time column, as well as at least one outcome column. 

### Exercise 3

In a paragraph, describe the number of rows for each source in the Population Table (Data, Preceptor Table, Population).

```{r justice-3}
question_text(NULL,
	message = "The Data category would have 2,089 rows, one for each poll respondent. The Preceptor Table would have as many rows as there are 18-29 year old Americans on Nov 13, 2013, in order to make the simple algebraic calculation of President Obama's approval among all young Americans. The Population would be larger than the Preceptor Table and consist of several cohorts of people, including multiple rows for a single individual as their opinion may have changed a few days before or after the poll, as well as new rows for people who may turn 18 a few days after the poll, and also people who turned 30 after the poll was conducted. ",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 4

How would each of the 3 Population sources (Data, Preceptor Table, and Population) differ in terms of the time column? Respond in a paragraph, making sure to include specific times in your response. 

```{r justice-4}
question_text(NULL,
	message = "Members of the wider Population would exist before the poll was conducted, after the poll was conducted, and well into the future, as the poll could have been conducted at any time. Because the question asks for the approval rating of young Americans on November 15, 2013, the Preceptor Table category would be exclusively composed of that date. Subjects from the data would have a time range between October 29 and November 16, 2013, because that was when the poll was conducted.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 5

In 2 sentences, what components of the Population Table would have unknown values?  

```{r justice-5}
question_text(NULL,
	message = "The approval outcome of Preceptor Table subjects would be unknown because we have no data on the attitudes of young Americans on November 15, 2013. We would know the approval outcome of 2,089 members of the Population whose data we collected in the poll, but the vast majority of young Americans approval of Obama would be unknown, including the attitudes of poll respondents both before and after the poll was conducted as their opinions could have changed.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 6

The following question was asked to poll respondents to assess their approval of President Obama: 

> In general, do you approve or disapprove of the job performance of Barack Obama as president?

In 2 sentences, explain why asking a different question to some respondents may challenge the *validity* of the approval column? 

```{r justice-6}
question_text(NULL,
	message = "The way a question is worded can heavily influence a person's response. As such, changing the question would change the meaning of the approval column, as people's outcomes may change depending on what question they were asked.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 7

The Harvard IOP poll was conducted between October 29 and November 13 of 2013. In 2 sentences, state one reason why the poll results may not be *stable* several days before or after the poll. 

```{r justice-7}
question_text(NULL,
	message = "A major news event that happened after the poll was conducted could cause the attitudes of young adults to shift dramatically. If this were to be the case, the poll would not be representitive of the respondents more current beliefs, and instead only reflect their past attitudes before the news event.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 8

The [press release revealing the poll results](https://iop.harvard.edu/sites/default/files_new/Harvard_PressReleaseFall2013%20.pdf) included a brief explanation of KnowledgePanel®, which was the platform used to conduct the poll:

> The web-enabled KnowledgePanel® is a probability-based panel designed to be representative of the
U.S. population. Initially, participants are chosen scientifically by a random selection of 
telephone numbers and residential addresses. Persons in selected households are then invited by
telephone or by mail to participate in the web-enabled KnowledgePanel®. For those who agree
to participate, but do not already have Internet access, GfK provides a laptop and ISP connection
at no cost. 

With knowledge of the sampling methodology, determine one group the poll may exclude (and explain why it excludes them), which could cause the poll to not be *representative* of all 18-29 year old Americans. Respond in 1 sentence. 

```{r justice-8}
question_text(NULL,
	message = "The poll would not represent 18-29 year old prisoners, as they could not be selected via random selection of telephone numbers and addresses.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 9

Good. Now let's turn our attention to the Data Generating Mechanism (DGM). Should our polling scenario be modeled by a normal or binomial distribution? Explain your reasoning in 2 sentences.  

```{r justice-9}
question_text(NULL,
	message = "Our polling scenario should be modeled by a binomial distribution, because we model the number of people who approve of President Obama (successes) over people who disapprove of him (failures). Because there are only 2 possibilities to model, the poll can be modeled by a binomial distribution",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

To create our models we will use the following binomial model: 

$$ T_a \sim B(\rho , n = 2089)$$

The total number of young Americans aged 18-29 who approve of President Obama, $T_a$, is modeled by a binomial distribution with the probability of one young American approving of President Obama, and 2,089 observations. 

### 

Use Justice to further increase your understanding of the situation at hand. Justice always consists of a Population Table, validity, stability, representativeness, and the Data Generating Mechanism.

## IOP study
### 

Whenever you want to find the value of a parameter, create a posterior distribution. 

### 

Recall our question: 

> Imagine that it is November 15, 2013. What percentage of young people (aged 18 to 29) approve of President Obama's performance?

### 

In order to answer the question, use the Harvard IOP poll to create the posterior distribution for the percentage of U.S 18-29 year olds who approved of President Obama in the fall of 2013. 

```{r}
ob_iop_ppd %>%
  ggplot(aes(x = approval)) +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 50) +
  scale_x_continuous(labels = scales::percent_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_light() +
  labs(title = "Posterior Probability Distribution",
       x = "Percentage of 18-29 year olds who approved of Obama on Nov 15, 2013",
       y = "Probability")
```

### Exercise 1

In order to create a binomial model, you must structure your data so that 1's represent successes and 0's represent failures. For structuring the responses for the Obama poll, it makes sense to represent those who approved of Obama's performance with 1's, and those who disapproved with 0's. 

Run `iop_results` to get a reminder of the poll results. 

```{r iop-study-1, exercise = TRUE}

```

### Exercise 2

First, input the 855 respondents who approved of President Obama's performance into your data. 

Use `tibble()` and set `approve` equal to `c()`. For the first element in the vector, repeat the number 1, 855 times. Hint: use the function `rep()` to repeat, passing what you want to repeat as the first argument, and the number of times you want to repeat it as the second argument. 

```{r iop-study-2, exercise = TRUE}

```

```{r iop-study-2-hint-1, eval = FALSE}
tibble(... = c(...))
```

```{r iop-study-2-hint-2, eval = FALSE}
tibble(... = c(rep(..., ...)))
```

### 

Your tibble should have 855 rows, representing 41% of the 2,089 poll respondents who approved of President Obama's performance. 

### Exercise 3

Next, input the 1,124 respondents who disapproved of President Obama's performance.

Copy your code from above. Add another `rep()` function as the second element in the vector, and repeat the number 0, 1124 times.

```{r iop-study-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r iop-study-3-hint-1, eval = FALSE}
tibble(... = c(rep(..., ...), rep(..., ...)))
```

### 

Your tibble should now have `r 855 + 1124` rows. Rows with 1's represent respondents who approved of President Obama's performance, and 0's represent those who disproved. 

The `r 855 + 1124` individuals in our tibble is less than the 2,089 individuals who initially completed the poll. This is because we excluded people who failed to respond, as we do not know whether or not they approved of Obama.  

### Exercise 4

Assign your code from above to an object named `iop_data`.

```{r iop-study-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r iop-study-4-hint-1, eval = FALSE}
Use the assignment operator <-  to do so.
```

### 

Excellent work. Now it's time to use the **rstanarm** package to fit a model for the data. 

### Exercise 5

Next we'll use `stan_glm()` to create a simple Bayesian model. When using `stan_glm()`, there are always four arguments that should be specified:

* The `data` argument tells `stan_glm()` what data frame to work with. Set `data` to `iop_data`. 
* The `family` argument tells `stan_glm()` what mathematical formula should be used to create our model. Set `family` to `binomial`.
* The `formula` argument tells `stan_glm()` what model is to be fitted. Because we have no predictors, we use the argument `formula = approve ~ 1`, which means that we only model the outcome based on the `approve` column of our data. 
* Set `refresh` to 0 in order to suppress the behavior of printing to the console, and `seed` to 2013 in order to get the same output every time we run the code.

```{r iop-study-5, exercise = TRUE}

```

```{r iop-study-5-hint-1, eval = FALSE}
stan_glm(data = ...,
         family = ...,
         formula = ..., 
         refresh = ...,
         seed = ...)
```

### 

You do not need to understand what the printed model means. 

### Exercise 6

Next, assign your model to an object named `iop_fit` to save it for future use.  

```{r iop-study-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r iop-study-6-hint-1, eval = FALSE}
Use the assignment operator <-  to do so.
```

### Exercise 7

Let's recreate our posterior distribution using `posterior_epred()`, assigning our code to a variable called `ob_iop_ppd`. Pass in `iop_fit` as the first argument, and then set the argument `newdata` equal to a `tibble()`. Within the `tibble()`, include `constant = 1`. 

```{r iop-study-7, exercise = TRUE}

```

```{r iop-study-7-hint-1, eval = FALSE}
ob_iop_ppd <- posterior_epred(..., 
                 newdata = ...)
```

### 

We use `constant = 1` as junk data to make sure our tibble has just 1 row. 

### Exercise 8

Copy your code from above. First pipe `as_tibble()` to your code. Then continue your pipe by renaming the column of the resulting tibble from `1` to `approval` by using `approval = 1` within `rename()`. **Remember to include backticks around 1**. 

```{r iop-study-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r iop-study-8-hint-1, eval = FALSE}
... %>%
  ... %>%
  rename(...)
```

```{r iop-study-8-hint-2, eval = FALSE}
Within rename, set approval equal to `1`. Make sure to include backticks around 1!
```

### Exercise 9

Finally, continue your pipe with `mutate()`. Within `mutate()`, set `study` to "iop". We uniformly assign "iop" to each row in our tibble in order to compare posteriors later on. 

```{r iop-study-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r iop-study-9-hint-1, eval = FALSE}
... %>%
  mutate(... = ...)
```

### Exercise 10

Type `ob_iop_ppd` below to view 4,000 draws from the posterior. 

```{r iop-study-10, exercise = TRUE}

```

### Exercise 11

Awesome! Now let's graph the draws from the posterior. First, start a pipe with `ob_iop_ppd`, and using `ggplot()` map `approval` to the x axis. 

```{r iop-study-11, exercise = TRUE}

```

```{r iop-study-11-hint-1, eval = FALSE}
ob_iop_ppd %>%
  ggplot(aes(... = ...))
```

### Exercise 12

Copy your code from the previous question and add the layer `geom_histogram()`. Within `geom_histogram()`, use `aes()` to set `y` equal to `after_stat(count/sum(count))` in order to convert the y-axis to percent values. Also set `bins` to 100. 

```{r iop-study-12, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r iop-study-12-hint-1, eval = FALSE}
... +
  geom_histogram(aes(... = ...),
                 bins = ...)
```

### Exercise 13

Great. Now add the layer `scale_x_continuous()` with the argument `labels` set to `scales::percent_format()`. Also add the layer `scale_y_continuous()`, with the argument `labels` also set to `scales::percent_format()`.

```{r iop-study-13, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r iop-study-13-hint-1, eval = FALSE}
... +
  scale_x_continuous(... = ...) +
  scale_y_continuous(... = ...)
```

### Exercise 14

To finish, use `labs()` to give your graph the appropriate title, subtitle, and axis labels. Also add the layer `theme_light()`. 

```{r iop-study-14, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

Reminder: Your plot should look something like this:

```{r}
ob_iop_ppd %>%
  ggplot(aes(x = approval)) +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100) +
  scale_x_continuous(labels = scales::percent_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_light() +
  labs(title = "Posterior Probability Distribution",
       x = "Percentage of 18-29 year olds who \n approved of Obama on Nov 15, 2013",
       y = "Probability")
```

### Exercise 15

Using the posterior, answer the initial question in 2 sentences: 

> Imagine that it is November 15, 2013. What percentage of young people (aged 18 to 29) approve of President Obama's performance?

Because the exact value of the parameter (the percentage of young Americans who approved of Obama's performance) is unknown, your answer should not be a single number, but instead a range of values that the true value of the parameter is likely to fall between.  

```{r iop-study-15}
question_text(NULL,
	message = "The bulk of the area under the distribution occurs between 42% and 44%, so it's likely that the percentage of all young American adults who approved of President Obama is between this range. However, there is also some chance that the percentage is as low as 40%, and as high as 46.5%.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Whenever you want to find the value of a parameter, create a posterior distribution. 

<!-- ## Predicting outcomes -->

<!-- Lesson: Posterior predictions are never the truth.  -->

<!-- Problem with teaching lesson: Because our posterior is very refined, the predictions are pretty accurate. If you uncomment the code below, you will see 5% is the largest difference between actual and predicted.  -->

<!-- ```{r} -->
<!-- min(ob_iop_ppd$approval) -->
<!-- max(ob_iop_ppd$approval) -->

<!-- iop_pred <- posterior_predict(iop_fit, newdata = tibble(constant = rep(1, 10))) %>% -->
<!--   as_tibble() %>%  -->
<!--   mutate(total = rowSums(across(`1`:`10`))) %>%  -->
<!--   select(total) -->

<!-- tibble(pop_pct = seq(from = .4, to = .47, by = .01)) %>% -->
<!--   mutate(n_ppl = map(pop_pct, ~ 0:10)) %>% -->
<!--   unnest(n_ppl) %>% -->
<!--   mutate(real_prob = map_depth(.x = n_ppl, .depth = 0, ~ dbinom(x = .x, size = 10, prob = pop_pct))) %>% -->
<!--   mutate(est_prob = map_dbl(n_ppl, ~ sum(iop_pred$total == .)/4000)) %>% -->
<!--   mutate(diff = real_prob - est_prob) %>% -->
<!--   mutate(pos = ifelse(diff > 0, TRUE, FALSE)) %>% -->
<!--   ggplot(aes(x = n_ppl, y = diff, fill = pos)) +  -->
<!--   geom_col() +  -->
<!--   facet_wrap(~pop_pct) +  -->
<!--   scale_fill_manual(values = c("red", "green")) -->

<!-- ``` -->


## Class study
### 

The center of a distribution approximates a parameter for an entire population, while the spread of a distribution represents the uncertainty surrounding the estimated parameter. The sample mean or proportion determines the center, while the number of observations in the sample determines the spread. 

We will use this methodology of comparing distributions to evenntually compare the posterior probability distributions of the Harvard IOP poll and a new Gov't class poll:

```{r}
bind_rows(ob_iop_ppd, class_ppd) %>%
  ggplot(aes(x = approval, fill = study)) +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100, alpha = .5, position = "identity") + 
  scale_x_continuous(labels = scales::number_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_light() +
  scale_fill_discrete(name = "Study", labels = c("Gov't Class", "Harvard IOP")) +
  labs(title = "Comparing Posterior Distributions of 2 Studies", 
       subtitle = "The differences between the studies can be expressed by \n
       the posterior means and spreads.",
       x = "Approval Percentage", 
       y = "Probability")
```

### 

At the exact same time as the Harvard IOP poll, a high school government class conducted their own Obama approval poll. The class randomly dialed U.S households, requesting to speak to an adult with the most recent birthday, and asked the following question:

> In general, do you approve or disapprove of the job performance of Barack Obama as president?

The class continued the poll until they received 200 responses. 

### Exercise 1

In one sentence, state a wider Population that the class poll may generalize. Make sure to include demographic characteristics, as well as a specific time period.  

```{r class-study-1}
question_text(NULL,
	message = "The poll was given to random U.S households. Assuming the dialing was truly random, and only adults answered the call, then the population of the survey could be all U.S adults a few days before and after the poll (ie between October 26 and November 16 of 2013).",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Using the class poll, we will attempt to answer the following question:

> Imagine that it is November 15, 2013. How does the percentage of U.S young adults aged 18-29 who approved of President Obama compare to the the percentage of all U.S adults who approved of him? 

### Exercise 2

Type `class` to review the results of the class poll. 

```{r class-study-2, exercise = TRUE}

```

### 

There appear to be 3 possible answers: approve, disapprove, or NA. 

### Exercise 3

Let's use the **skimr** package to see how many levels there are in the `response` column. Use `skim()`, passing in `class`. 

```{r class-study-3, exercise = TRUE}

```

```{r class-study-3-hint-1, eval = FALSE}
skim(...)
```

### 

Looking at n_unique for our single character column, we see that there are only 2 unique values. We also see that there are 32 missing values. This corresponds with our initial belief that there are only 3 possible values: approve, disapprove, or NA. Always take a thorough look at your data to make sure there are not hidden levels that are not visible at first glance. 

### Exercise 4

Although `skim()` identifies how many levels each column in our data has, it does not display the frequencies of each level. To do this, start a pipe with `class`, and pipe on the function `count()`. Within `count()`, use the sole argument `response`. 


```{r class-study-4, exercise = TRUE}

```

```{r class-study-4-hint-1, eval = FALSE}
... %>%
  count(...)
```

### 

We can now easily view the results of the class poll: Out of the 200 poll respondents, 64  approved of President Obama, 104 disapproved, and answers are missing from 32.

### Exercise 5

Some respondents, denoted by NA's, failed to answer the question. Like the Harvard IOP poll, let's drop NA values. 

Pipe on `drop_na()` to your code from above. 

```{r class-study-5, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r class-study-5-hint-1, eval = FALSE}
... %>%
  drop_na()
```

### 

In order to create a binomial model, the next step is to transfrom the poll summary into a binomial format. Those who approved of Obama's performance should be represented with 1's, and those who disapproved with 0's.

### Exercise 6

First, input the 64 respondents who approved of President Obama's performance into your data.

Use `tibble()` and set `approve` equal to `c()`. For the first element in the vector, repeat the number 1, 64 times. Hint: use the function `rep()` to repeat, passing what you want to repeat as the first argument, and the number of times you want to repeat it as the second argument. 

```{r class-study-6, exercise = TRUE}

```

```{r class-study-6-hint-1, eval = FALSE}
tibble(... = c(...))
```

```{r class-study-6-hint-2, eval = FALSE}
tibble(... = c(rep(..., ...)))
```

### 

Your tibble should have 64 rows, representing the class poll respondents who approved of President Obama's performance.

### Exercise 7

Next, input the 104 respondents who disapproved of President Obama's performance.

### 

Copy your code from above. Add another `rep()` function as the second element in the vector, and repeat the number 0, 104 times.

```{r class-study-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r class-study-7-hint-1, eval = FALSE}
tibble(... = c(rep(..., ...), rep(..., ...)))
```

### 

Your tibble should now have `r 64 + 104` rows. Rows with 1's represent respondents who approved of President Obama's performance, and 0's represent those who disproved. 

The `r 64 + 104` individuals in our tibble is less than the 200 individuals who initially completed the poll. This is because we excluded people who failed to respond, as we do not know whether or not they approved of Obama.  

### Exercise 8

Assign your code from above to an object named `class_data`.

```{r class-study-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r class-study-8-hint-1, eval = FALSE}
Use the assignment operator <-  to do so.
```

### 

Excellent work. Now it's time to use the **rstanarm** package to fit a model for the data. 

### Exercise 9

Next we'll use `stan_glm()` to create a simple Bayesian model. When using `stan_glm()`, there are always four arguments that should be specified:

* The `data` argument tells `stan_glm()` what data frame to work with. Set `data` to `class_data`. 
* The `family` argument tells `stan_glm()` what mathematical formula should be used to create our model. Set `family` to `binomial`.
* The `formula` argument tells `stan_glm()` what model is to be fitted. Because we have no predictors, we use the argument `formula = approve ~ 1`, which means that we only model the outcome based on the `approve` column of our data. 
* Set `refresh` to 0 in order to suppress the behavior of printing to the console, and `seed` to 10 in order to get the same output every time we run the code.

```{r class-study-9, exercise = TRUE}

```

```{r class-study-9-hint-1, eval = FALSE}
stan_glm(data = ...,
         family = ...,
         formula = ..., 
         refresh = ...,
         seed = ...)
```

### 

You do not need to understand what the printed model means. 

### Exercise 10

Next, assign your model to an object named `class_fit` to save it for future use.  

```{r class-study-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r class-study-10-hint-1, eval = FALSE}
Use the assignment operator <-  to do so.
```

### Exercise 11

Let's recreate our posterior distribution using `posterior_epred()`, assigning our code to a variable called `class_ppd`. Pass in `class_fit` as the first argument, and then set the argument `newdata` equal to a `tibble()`. Within the `tibble()`, include `constant = 1`. 

```{r class-study-11, exercise = TRUE}

```

```{r class-study-11-hint-1, eval = FALSE}
class_ppd <- posterior_epred(..., 
                 newdata = ...)
```

### 

We use `constant = 1` as junk data to make sure our tibble has just 1 row. 

### Exercise 12

Copy your code from above. First pipe `as_tibble()` to your code. Then continue your pipe by renaming the column of the resulting tibble from `1` to `approval` by using `approval = 1` within `rename()`. **Remember to include backticks around 1**. 

```{r class-study-12, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r class-study-12-hint-1, eval = FALSE}
... %>%
  ... %>%
  rename(...)
```

```{r class-study-12-hint-2, eval = FALSE}
Within rename, set approval equal to `1`. Make sure to include backticks around 1!
```

### Exercise 13

Finally, continue your pipe with `mutate()`. Within `mutate()`, set `study` to "class". 
We uniformly assign "class" to each row in our tibble in order to compare posteriors later on.

```{r class-study-13, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r class-study-13-hint-1, eval = FALSE}
... %>%
  mutate(... = ...)
```

### Exercise 14

Type `class_ppd` below to view 4,000 draws from the posterior. 

```{r class-study-14, exercise = TRUE}

```

### Exercise 15

We will now attempt to answer the question we began with: 

> Imagine that it is November 15, 2013. How does the percentage of U.S young adults aged 18-29 who approved of President Obama compare to the the percentage of all U.S adults who approved of him? 

### 

In order to compare the two posteriors, combine the Harvard IOP posterior with the class study posterior using `bind_rows()`. Include `ob_iop_ppd` as the first argument, and `class_ppd` as the second argument. 

```{r class-study-15, exercise = TRUE}

```

```{r class-study-15-hint-1, eval = FALSE}
bind_rows(..., ...)
```

### Exercise 16

Copy your code from above, and continue your pipe using `ggplot()`. Map `approval` to the x-axis, and `study` to the fill. 

```{r class-study-16, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r class-study-16-hint-1, eval = FALSE}
... %>%
  ggplot(... = ..., ... = ...)
```

### Exercise 17

Add the layer `geom_histogram()`, using `aes()` as the first argument to set `y` equal to `after_stat(count/sum(count))` in order to convert the y-axis to percent values. Also set `bins` to 100, `alpha` to .5, and `position` to "identity".  

```{r class-study-17, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r class-study-17-hint-1, eval = FALSE}
... +
  geom_histogram(aes(... = ...),
                 bins = ..., 
                 alpha = ...,
                 position = ...)
```

### Exercise 18

Great. Now add the layer `scale_x_continuous()` with the argument `labels` set to `scales::percent_format()`. Also add the layer `scale_y_continuous()`, with the argument `labels` also set to `scales::percent_format()`.

```{r class-study-18, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r class-study-18-hint-1, eval = FALSE}
... +
  scale_x_continuous(... = ...) +
  scale_y_continuous(... = ...)
```

### Exercise 19

Now add the layer `scale_fill_discrete()` to change the legend labels. Within `scale_fill_discrete()`, set `name` to "Study", and `labels` to a vector containing "Gov't Class" and "Harvard IOP" (in that order). 


```{r class-study-19, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r class-study-19-hint-1, eval = FALSE}
... +
  scale_fill_discrete(... = ..., ... = ...)
```

```{r class-study-19-hint-2, eval = FALSE}
Use c() to create a vector with 2 elements. Make sure to include "Gov't Class" as the first element, and "Harvard IOP" as the second element. 
```

### Exercise 20

To finish, use `labs()` to give your graph the appropriate title, subtitle, and axis labels. Also add the layer `theme_light()`.

```{r class-study-20, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

Your plot should look something like this:

```{r}
bind_rows(ob_iop_ppd, class_ppd) %>%
  ggplot(aes(x = approval, fill = study)) +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100, alpha = .5, position = "identity") + 
  scale_x_continuous(labels = scales::number_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_light() +
  scale_fill_discrete(name = "Study", labels = c("Gov't Class", "Harvard IOP")) +
  labs(title = "Comparing Posterior Distributions of 2 Studies", 
       subtitle = "The differences between the studies can be expressed by \n
       the posterior means and spreads.",
       x = "Approval Percentage", 
       y = "Probability")
```

### 

You have successfully created the posteriors for two different Obama approval polls. The next step is to compare them, in order to answer the question: 

> Imagine that it is November 15, 2013. How does the percentage of U.S young adults aged 18-29 who approved of President Obama compare to the the percentage of all U.S adults who approved of him? 

### Exercise 21

First, approximate the centers of by taking the `mean()` of the `approval` column for both `ob_iop_ppd` and `class_ppd`.  

```{r class-study-21, exercise = TRUE}

```

```{r class-study-21-hint-1, eval = FALSE}
mean(ob_iop_ppd$...)
mean(class_ppd$...)
```

### 

Although you can determine the centers of each posterior using the graph visually, it's important to understand that the mean of the posterior determines its center. 

### Exercise 22

In a paragraph, compare the 2 posteriors in terms of their **centers**. What do you think causes the posteriors to be centered differently? Make sure to use the term *population parameter* in your response. 

```{r class-study-22}
question_text(NULL,
	message = "The poll was given to random U.S households. Assuming the dialing was truly random, and only adults answered the call, then the population of the survey could be all U.S adults a few days before and after the poll (ie between October 26 and November 16 of 2013).",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 23

Next, calculate the variation of each distribution by finding the standard deviation using `sd()` of the `approval` column for both `ob_iop_ppd` and `class_ppd`.  

```{r class-study-23, exercise = TRUE}

```

```{r class-study-23-hint-1, eval = FALSE}
sd(ob_iop_ppd$...)
sd(class_ppd$...)
```

### 

It is important to realize that the standard deviation quantifies the spread of a distribution, giving its shape. 

### Exercise 24

In a paragraph, compare the 2 posteriors in terms of their **spread**. What do you think causes the difference in spread? Make sure to use the terms *uncertainty* and *observations* in your answer. 

```{r class-study-24}
question_text(NULL,
	message = "The poll was given to random U.S households. Assuming the dialing was truly random, and only adults answered the call, then the population of the survey could be all U.S adults a few days before and after the poll (ie between October 26 and November 16 of 2013).",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Whenever you want to describe a distribution, consider its spread and center. The center of a distribution approximates a parameter for an entire population, while the spread of a distribution represents the uncertainty surrounding the estimated parameter. Use the sample mean or proportion to find the center, and the number of observations in the sample to determine the spread. 

## Predicting outcomes
### 

Posterior predictive draws have certain properties: 

- With a large enough sample size, posterior predictive distributions are normally distributed.

- The estimated population parameter determined by the center of the posterior has a large effect on the predictive draws, while the spread of the posterior has a small effect. 

- Two different posterior predictions will be the most similar near the center, and the most different near the extremes. 

### 

To illustrate the above properties, we will answer the following question: 

> Imagine that it is November 15, 2013. For each poll, how many people would approve of President Obama in a room of 20 people? 

To answer this question, we must use `posterior_predict()` for both the IOP and Gov't class polls, using 20 observations, and compare the results:

```{r}
bind_rows(iop_predictions, class_predictions) %>%
  ggplot(aes(x = total, fill = poll)) +
  geom_histogram(aes(y = after_stat(count/sum(count))), position = "identity", alpha = .5, bins = 50) +
  scale_fill_manual(values = c("#e01919", "#213fd1")) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(title = "Posterior Probability Distribution",
       subtitle = "Number of Obama approvers in a room of 20 people for 2 different polls",
       y = "Probability",
       x = "Number of Obama Approvers in Room")
```


### Exercise 1

First, let's create the posterior predictions for the IOP poll. 

Within the `posterior_predict()` function, pass in `iop_fit` as the first argument, and then set the argument `newdata` equal to a `tibble()`. Within the `tibble()`, set `constant` to a vector that repeats the number 1, 20 times. Hint: use the function `rep()` to repeat, passing what you want to repeat as the first argument, and the number of times you want to repeat it as the second argument. 

Assign your code to a variable named `iop_predictions`. 

```{r predicting-outcomes-1, exercise = TRUE}

```

```{r predicting-outcomes-1-hint-1, eval = FALSE}
iop_predictions <- posterior_predict(..., 
                  ... = tibble(constant = ...))
```

```{r predicting-outcomes-1-hint-2, eval = FALSE}
iop_predictions <- posterior_predict(..., 
                  ... = tibble(constant = rep(..., ...)))
```

### 

We use pass a tibble with 20 rows into `newdata` because we want to estimate the number of red draws with a shovel size of 20. 

### Exercise 2

Copy your code from above and pipe on `as_tibble()`. Then type `iop_predictions` to view the results. 

```{r predicting-outcomes-2, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r predicting-outcomes-2-hint-1, eval = FALSE}
... %>%
  as_tibble()
```

### 

Each of the 4,000 rows represents one posterior prediction of the number of Obama approvers in a room of size 20. Each column represents the 20 individuals in the room, with 0's representing people who disapprove of President Obama, and 1's representing people who approve of him. 

### Exercise 3

Let's find the total number of people who approve of Obama in each prediction. Copy your code from above and create a column named `total` using `mutate()`. Set `total` to `rowSums(across(1:20))`, making sure to surround both the 1 and 20 in back ticks! Then continue your pipe and select the `total` column.

```{r predicting-outcomes-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r predicting-outcomes-3-hint-1, eval = FALSE}
... %>%
  mutate(total = ...) %>%
  select(...)
```

### 

Instead of having 20 columns, one for the results of each individual, using `rowSums()` allows us to find the sum across our rows and only with the total number of Obama approvers. 

### Exercise 4

Finally, add another column called `poll`, and assign all rows the value "IOP poll" so we can compare poll predictions later on. 


```{r predicting-outcomes-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r predicting-outcomes-4-hint-1, eval = FALSE}
mutate(poll = ...)
```

### Exercise 5

Great work! Now let's create the posterior predictions for the Gov't class poll. 

Because most of the code is the same, copy your code from above, making sure to change a few key features. First, change the variable name from `iop_predictions` to `class_predictions`. Next, replace `iop_fit` with `class_fit`. Finally, change the uniformly assigned name in the `poll` column from "IOP poll" to "Class poll". 

Assign your code to a variable named `class_predictions`. 

```{r predicting-outcomes-5, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

### 

Great work! You now have the posterior predictions for the IOP poll saved as `iop_predictions`, and the predictions from the Gov't class poll saved as `class_predictions`. 

### Exercise 6

Now combine the two polls into one tibble using `bind_rows()`. Pass in `iop_predictions` as the first argument, and `class_predictions` as the second. 

```{r predicting-outcomes-6, exercise = TRUE}

```

```{r predicting-outcomes-6-hint-1, eval = FALSE}
bind_rows(..., ...)
```

### 

Our tibble now has 8,000 rows, half from the IOP poll predictions and half from the class poll predictions. Again, each row can be thought of as a simulation of a room of 20 people, with the `total` column displaying the predicted number of Obama approvers in that room. 

### Exercise 7

Now let's graph our results. Use `ggplot()` on your code from above, and map `total` to the x-axis and `poll` to fill. 

```{r predicting-outcomes-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r predicting-outcomes-7-hint, eval = FALSE}
... %>%
  ggplot(aes(x = ..., fill = ...))
```

###

Because we are using `geom_histogram()`, bar height will be calculated by the number of observations for each value of `total`. 

### Exercise 8

Copy your code from the previous question and add the layer `geom_histogram()`. Within `geom_histogram()`, use `aes()` to set `y` equal to `after_stat(count/sum(count))` in order to convert the y-axis to percent values. Also set `bins` to 50,`alpha` to .5, and `position` to identity. 

```{r predicting-outcomes-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r predicting-outcomes-8-hint, eval = FALSE}
... +
  geom_histogram(aes(y = ...),
                 bins = ...,
                 alpha = ...,
                 position = ...)
```

###

Unfortunately, the default colors are hard to differentiate visually. Instead, let's choose our own custom colors. 

### Exercise 9

Now add a layer with `scale_fill_manual()` to change the color of our bars. Inside `scale_fill_manual()`, set `values` to a vector that combines "#e01919" and #213fd1".

```{r predicting-outcomes-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r predicting-outcomes-9-hint, eval = FALSE}
... +
  scale_fill_manual(values = c(..., ...))
```

###

Another issue is that while we are attempting to create a posterior probability distribution, the y-axis is formatted as decimals instead of percents.

### Exercise 10

Add the layer `scale_y_continuous()` with the argument `labels` set to `scales::percent_format()`.

```{r predicting-outcomes-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r predicting-outcomes-10-hint, eval = FALSE}
... +
   scale_y_continuous(labels = ...)
```

### Exercise 11

To finish, use `labs()` to give your graph the appropriate title, subtitle, and axis labels. 

```{r predicting-outcomes-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

Your plot should look something like this:

```{r}
bind_rows(iop_predictions, class_predictions) %>%
  ggplot(aes(x = total, fill = poll)) +
  geom_histogram(aes(y = after_stat(count/sum(count))), position = "identity", alpha = .5, bins = 50) +
  scale_fill_manual(values = c("#e01919", "#213fd1")) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(title = "Posterior Probability Distribution",
       subtitle = "Number of Obama approvers in a room of 20 people for 2 different polls",
       y = "Probability",
       x = "Number of Obama Approvers in Room")
```


###

Great work! Look at your graph and begin to examine the trends. Keep in mind that the red bars represent that the class poll has a higher probability for a room to have a given number of Obama approvers designated by the x-axis, the blue bars represent the class poll having a higher probability, and the purple is the overlap. 

### Exercise 12

In 2 sentences, use evidence from your plot to support the following property of posterior predictive distributions: 

> With a large enough sample size, posterior predictive distributions are normally distributed.


```{r predicting-outcomes-12}
question_text(NULL,
	message = "In the plot there is a low probability for there to be 1-3 Obama approvers, but for each subsequent number of predicted Obama approvers the probabliity increases until it reaches the center, where the graph decreases symetrically to how it increased. This bell shaped distribution is well approximated by the normal distribution.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

Note that because we are graphing two different distributions at once, the graph is not as symmetrical as it would be for a single distribution. 

### Exercise 13

In 2 sentences, use evidence from your plot to support the following property of posterior predictive distributions: 

> The estimated population parameter has a large effect on the probability of predictive draws.


```{r predicting-outcomes-13}
question_text(NULL,
	message = "The graph has more red bars indicating the class poll on the left, because the class poll had a lower approval percentage and as such there are less Obama approvers predicted to be in a room. On the other hand, the higher approval percentage of the Harvard IOP poll causes more blue bars to be shown on the right, as the distribution is shifted over and higher numbers of Obama approvers are more likely.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 14

In 2 sentences, use evidence from your plot to support the following property of posterior predictive distributions: 

> Two different posterior predictions will be the most similar near the center, and the most different near the extremes. 

```{r predicting-outcomes-14}
question_text(NULL,
	message = "When there are 8 predicted Obama supporters, the bar is nearly entirely purple because predictions from the IOP poll and class poll have a similar probability of having 8 Obama approvers. However, as the number of Obama approvers become more extreme, the bars become less purple and more blue or red, representing that one poll has a significantly higher probability of acheiving some value of Obama approvers.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

Notice the magnitude of the differences between the polls for when the predicted number of Obama approvers is 5 or 11. Seeing these large differences will be crucial to tackle our subsequent probability question that compares the similarity between the two polls, as large differences mean it is less likely for two rooms of the different poll respondents to be identical. 

## Probability 
### 

No matter how complex, virtually all probability problems involve finding the area under a curve. 

### 

Let's attempt to answer the following question: 

> Imagine that it is November 15, 2013. What is the probability that a group of IOP poll respondents and a group of the Gov't class poll respondents would have the same number of people who approve of President Obama? 

Because this is a probability question, we can model the probabilities as areas under a curve:

```{r}
both_polls %>%
  pivot_longer(names_to = "group", values_to = "num_draws", cols = 3:4) %>%
  ggplot(aes(x = total, y = num_draws, fill = group)) + 
  facet_wrap(~num_people) +
  geom_col(position = "identity", alpha = .5) +
  scale_fill_manual(values = c("#e01919", "#213fd1")) + 
  labs(title = "Similarities and Differences for 2 Different Rooms",
       subtitle = "Each frame represents a different room size",
       y = "Number of Posteiror Draws",
       x = "Number of Obama Approvers in Room")
```

### 

First let's break down the question. We want to find the probability of two "groups", which we will call rooms, being identical. What we must realize is that the probability is contingent on the size of the room. For example, we'd expect there to be a relatively large chance that 2 rooms with 3 people in them to have the same number of people who approve of President Obama. However, there should be almost no chance that a room of size 300 would have the same number of people who approve of President Obama. 

To answer the question, we will make predictions from draws of the posterior using the `posterior_predict()` function, and then calculate the differences between the two rooms. To make predictions for the room filled with IOP poll respondents we will use the posterior we made earlier using the Harvard IOP poll, and use the class poll to make predictions for the room filled with all Americans. 

### Exercise 1

Because the probability of the two rooms being identical is contingent on room size, we will make posterior predictions for 20 different room sizes: from 1 person, all the way to 20 people.

Initialize a `tibble()`, with the column `num_people` equal to a range of integers from 1 to 20

```{r probability-1, exercise = TRUE}


```

```{r probability-1-hint-1, eval = FALSE}
tibble(... = ...:...)
```

### Exercise 2

Now create a column called `predictions` using `mutate()`. Set `predictions` equal to `map()`, using `num_people` for the first argument, and a ~ followed by `posterior_predict()` for the second. 

Within `posterior_predict()` pass in our `iop_fit` model as the first argument, and set the second argument `newdata` equal to a `tibble()`. 

Within the `tibble()`, set `constant` to the `rep()` function, passing in the number 1 as the first argument, and a `.` as the second. 

```{r probability-2, exercise = TRUE}


```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-2-hint-1, eval = FALSE}
... %>%
  mutate(... = map(..., ~ ...))
```

```{r probability-2-hint-2, eval = FALSE}
Within map use posterior_predict():
posterior_predict(..., newdata = tibble(... = rep(..., ...)))
```

### 

For each room size we use the `map()` function to pass the room size into `posterior_predict()`, creating posterior predictions for each room size. 

### Exercise 3

Copy your code from above. Create a new column called `total` and set it equal to `map()`. Within `map()`, use `predictions` as the first argument, and a ~ followed by `rowSums()` as the second. Pass the `.` operator into `rowSums()`.

```{r probability-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-3-hint-1, eval = FALSE}
... %>%
  mutate(... = map(..., ~ ...))
```

### 

We use `rowSums()` in order to calculate the total number of people who approve of Obama within a room. 

### Exercise 4

Continue your pipe with the function `unnest()`. Pass in `total` as the sole argument. 

```{r probability-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-4-hint-1, eval = FALSE}
... %>%
  unnest(...)
```

### 

The `unnest()` function expands `total` out of list form into individual integers. 

### Exercise 5

Now group your tibble by `num_people` and `total` using the `group_by()` function. 

```{r probability-5, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-5-hint-1, eval = FALSE}
... %>%
  group_by(..., ...)
```

### Exercise 6

Continue your pipe one last time using the `summarize()` function. Within `summarize()`, set `num_draws` to `n()`. Also set the `.groups` argument to "drop". 

```{r probability-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-6-hint-1, eval = FALSE}
... %>%
  summarize(... = ..., ... = ...)
```

### 

In essence, the 4,000 draws from `posterior_predict()` represent 4,000 simulations of one room size. The `n()` function tallies the predicted number of Obama approvers across for each room size across all the simulations.  

### Exercise 7

Assign your code from above to an object named `young`.

```{r probability-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-7-hint-1, eval = FALSE}
Use the assignment operator <-  to do so.
```

### 

The `young` tibble represents the predictions for young Americans aged 18-29. 

### Exercise 8

To simulate the predictions for all Americans we can recreate the exact same tibble as above, but using the posterior from the class survey instead of the posterior from the IOP survey. 

### 

Copy your code from above, and replace `iop_fit` with `class_fit`. Also save the object with the name `young` instead of `all`.

```{r probability-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>


### 

We now have a tibble named `young` with the predictions for young Americans, and a tibble named `all` with the predictions for all Americans. 

### Exercise 9

To compare the predictions for young Americans with the predictions for all Americans, join the tibbles together using `inner_join()`. Pass in `all` as the first argument and `young` as the second. For the third argument, set `by` equal to a vector with 2 elements, "num_people" and "total". 

```{r probability-9, exercise = TRUE}

```

```{r probability-9-hint-1, eval = FALSE}
inner_join(..., ..., ... = c(..., ...))
```

### Exercise 10

Copy your code from above. Use the `rename()` function to rename the column `num_draws.x` to `all_draws`, and `num_draws.y` to `young_draws`. Remember to use the new_name = old_name syntax. 

```{r probability-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-10-hint-1, eval = FALSE}
... %>%
  rename(... = ..., ... = ...)
```

### Exercise 11

Save your tibble to a variable called `both_polls`.

```{r probability-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-11-hint-1, eval = FALSE}
Use the assignment operator <-  to do so.
```

### Exercise 12

Remember our statement from the beginning: 

No matter how complex, virtually all probability problems involve finding the area under a curve.

### 

Run the following code to visualize the predictions from each room. 

```{r probability-12, exercise = TRUE}
both_polls %>%
  pivot_longer(names_to = "group", values_to = "num_draws", cols = 3:4) %>%
  ggplot(aes(x = total, y = num_draws, fill = group)) + 
  facet_wrap(~num_people) +
  geom_col(position = "identity", alpha = .5) +
  scale_fill_manual(values = c("#e01919", "#213fd1"), labels = c("All Americans", "Young Americans"), name = "Group") + 
  labs(title = "Similarities and Differences for 2 Different Rooms",
       subtitle = "Each frame represents a different room size",
       y = "Number of Posteiror Draws",
       x = "Number of Obama Approvers in Room")
```

### 

A mostly purple bar indicates that the room of young Americans and all Americans are likely to have a similar number of Obama approvers designated by the x-axis. Red bars indicate that the room with all Americans is more likely to have the number of Obama supporters designated by the x-axis, while blue bars indicate the same phenomena with young Americans. 

### 

Notice how there is more cummilative non-purple area as the room size increases: as room size increases, the room of young Americans and the room of all Americans become more different. 

### Exercise 13

Let's quantify the differences between the two rooms. Start a pipe with `both_polls` and pipe on `rowwise()` to initiate operations across rows. 

```{r probability-13, exercise = TRUE}

```

```{r probability-13-hint-1, eval = FALSE}
... %>%
  ...
```

### Exercise 14

Create a column named `lrg_poll` using `mutate()`, and set it equal to the `max()` function. Within `max()`, use `c_across()` to create a vector with 2 elements: "all_draws" and "young_draws". 

```{r probability-14, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-14-hint-1, eval = FALSE}
... %>%
  mutate(... = max(c_across(..., ...)))
```

### 

`lrg_poll` represents the poll with the greatest number of predictive draws for a specific number of Obama approvers. In the area graph above, `lrg_poll` is the tallest bar for each x value. 

### Exercise 15

Create another column named `sml_poll` using `mutate()`, and set it equal to the `min()` function. Within `min()`, use `c_across()` to create a vector with the same 2 elements: "all_draws" and "young_draws". 

```{r probability-15, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-15-hint-1, eval = FALSE}
... %>%
  mutate(... = min(c_across(..., ...)))
```

### 

`sml_poll` represents the poll with the lesser number of predictive draws, indicating that it's less likely for that room of Americans to have some number of Obama approvers. In the area graph above, `sml_poll` is represented by the shortest bar. 

### Exercise 16

To finish operations across rows, add `ungroup()` to your pipe. Next, create a new column called `pct`. Set `pct` equal to `sml_poll` divided by `lrg_poll`. 

```{r probability-16, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-16-hint-1, eval = FALSE}
... %>%
  ... %>%
  mutate(... = .../...)
```

### 

The `pct` column quantifies how similar or different the rooms of young Americans and all Americans are. If the two rooms are predicted to have a similar number of Obama approvers (area bar is mostly purple), then `pct` will be closer to 1. If the two rooms are less similar and have drastically different predictions for a number of Obama approvers, `pct` will be closer to 0. 

### Exercise 17

Let's visualize the `pct` differences between the room of young Americans and all Americans. Copy your code from above, and use `ggplot()` to map `total` to the x-axis and `pct` to the y-axis. Add the layer `geom_col()`, and `facet_wrap()` by `num_people` (Make sure to include a ~ in `facet_wrap()`). To finish, use `labs()` to give your graph the appropriate title, subtitle, and axis labels.

```{r probability-17, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

Your plot should look something like this:

```{r}
both_polls %>%
  rowwise() %>%
  mutate(lrg_poll = max(c_across(c("all_draws", "young_draws")))) %>%
  mutate(sml_poll = min(c_across(c("all_draws", "young_draws")))) %>%
  ungroup() %>%
  mutate(pct = sml_poll/lrg_poll) %>%
  ggplot(aes(x = total, y = pct)) + 
  facet_wrap(~num_people) +
  geom_col() + 
  labs(title = "Percent Difference for 2 Rooms", 
       subtitle = "Each frame represents a different room size",
       y = "Percent",
       x = "Number of Obama Approvers in Room")
```

```{r probability-17-hint-1, eval = FALSE}
... %>%
  ggplot(aes(... = ..., ... = ...)) + 
  geom_col() + 
  facet_wrap(~ ) + 
  labs(title = ...,
       subtitle = ...,
       x = ...,
       y = ...)
```

### 

Each bar represents the percent difference for the room of young Americans and all Americans for the number of predicted Obama approvers designated by the x-axis. For small room sizes the bars are close to 100%, because the rooms are likely to be similar. Notice that for larger room sizes, the bars are tall for moderate numbers of predicted Obama supporters, but short for extreme numbers of Obama supporters. 


### Exercise 18

Copy your code from above, but delete the `ggplot()`, `geom_col()`, `facet_wrap()`, and `labs()` layers (we no longer wish to visualize the percent differences).  Instead, group your tibble by `num_people` using `group_by()`. 

```{r probability-18, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-18-hint-1, eval = FALSE}
... %>%
  group_by(...)
  
```

### Exercise 19

Continue your pipe with `summarize()`. Within `summarize()`, set `prob_rooms_are_same` to `round()`. Pass in the `prod()` function with the sole argument `pct` as the first argument of `round()`, and set `digits` to 6 as the second argument. 

```{r probability-19, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r probability-19-hint-1, eval = FALSE}
... %>%
  summarize(... = round(..., ... = ...))
```

```{r probability-19-hint-2, eval = FALSE}
... %>%
  summarize(... = round(prod(...), ... = ...))
```

### 

Because the probabilities for each number of Obama approvers in a room are independent from one another, we use the `prod()` function to multiply them. You can go back to the earlier visualization of `pct` and envision multiplying the bars together. If all the bars are tall then the final probability will be large. Multiplying by shorter bars will cause the final probability to decrease. 

### Exercise 20

The tibble you have created answers our question: 

> Imagine that it is November 15, 2013. If there were two rooms of the same size, one filled with all American adults, and one filled with just 18-29 year olds, what is the probability that the rooms will have the same number of people who approve of Obama?

Each value of `prob_rooms_are_same` represents the probability that the two rooms are the same for a specific room size! Use your tibble to answer the following question: 

What is the probability that on November 15, 2013, a single person randomly chosen from a group of young Americans aged 18-29 and a group of all adult Americans would both either approve of disapprove of President Obama? If we knew the actual percentage of young Americans and all Americans who approved of Obama, how do you think our answer would change, if at all? Respond in 2 sentences, making sure to use the term *uncertainty* in your response.  

```{r probability-20}
question_text(NULL,
	message = "There is about an 81% chance that the two people would both either approve or disapprove of President Obama. If we knew the actual percentage of young Americans and all Americans who approved of President Obama on November 15, 2013, the probability would most likely be much higher, because the answer would become a simple probability calculation that would not have to factor in uncertainty regarding the actual value of each percentage.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

No matter how complex, virtually all probability problems involve finding the area under a curve. 

## Summary
### 

By completing this tutorial, you have successfully conquered multiple real world problems like a professional. You first analyzed the Data and Preceptor Table in *Wisdom* and the Population Table in *Justice* to determine whether or not the data can answer the questions. Next, you created a posterior for the Harvard IOP survey to quantify your uncertainty about the true value of a population parameter.  You then learned to describe distributions in terms of their means and variations in order to accurately describe their differences. Finally, you hopefully realized that all probability problems, no matter how complex, can be broken down to finding the area under a graph!

### 

Great work!

```{r download-answers, child = "../../child_documents/download_answers.Rmd"}

```
